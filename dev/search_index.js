var documenterSearchIndex = {"docs":
[{"location":"guides/preprocessing/#Preprocessing","page":"Preprocessing","title":"Preprocessing","text":"ConicIP includes a preprocessing wrapper that removes redundant constraints before solving. This can prevent numerical issues caused by rank-deficient constraint matrices.","category":"section"},{"location":"guides/preprocessing/#When-to-Use-Preprocessing","page":"Preprocessing","title":"When to Use Preprocessing","text":"Use preprocess_conicIP instead of conicIP when:\n\nThe equality constraint matrix G may have redundant rows (i.e., rank(G) < size(G, 1))\nThe combined matrix [Q  A'  G'] may be rank-deficient\nYou receive :Error or :Abandoned status from the solver due to singular KKT systems","category":"section"},{"location":"guides/preprocessing/#Usage","page":"Preprocessing","title":"Usage","text":"preprocess_conicIP has the same signature as conicIP and passes all keyword arguments through:\n\nsol = preprocess_conicIP(Q, c, A, b, cone_dims, G, d; verbose=false)","category":"section"},{"location":"guides/preprocessing/#What-It-Does","page":"Preprocessing","title":"What It Does","text":"The preprocessor performs two steps:\n\nEquality constraint reduction: Uses imcols to identify and remove linearly dependent rows from G and d, ensuring rank(G) = size(G, 1).\nDual constraint reduction: Checks that the combined system [Q  A'  G'] has full row rank. If not, it removes dependent columns to restore full rank.\n\nAfter preprocessing, the reduced problem is passed to conicIP.","category":"section"},{"location":"guides/preprocessing/#The-imcols-Function","page":"Preprocessing","title":"The imcols Function","text":"imcols identifies independent columns (rows) in a linear system Ax = b. It returns the indices of a maximal linearly independent subset and checks consistency of the system.\n\nusing ConicIP, SparseArrays\n\nA = sparse([1.0 2.0 3.0;\n            2.0 4.0 6.0;   # redundant (2× row 1)\n            0.0 1.0 1.0])\nb = [1.0; 2.0; 1.0]\n\n# imcols returns indices of independent rows\nidx = ConicIP.imcols(A', b)","category":"section"},{"location":"guides/preprocessing/#Example","page":"Preprocessing","title":"Example","text":"using ConicIP, SparseArrays, LinearAlgebra, Random\nRandom.seed!(42)\n\nn = 5\nQ = sparse(1.0I, n, n)\nc = randn(n)\n\nA = sparse(1.0I, n, n)\nb = zeros(n)\ncone_dims = [(\"R\", n)]\n\n# Redundant equality constraints: row 3 = row 1 + row 2\nG = [1.0 1.0 0.0 0.0 0.0;\n     0.0 0.0 1.0 1.0 0.0;\n     1.0 1.0 1.0 1.0 0.0]   # redundant!\nd = [1.0; 1.0; 2.0]\n\n# preprocess_conicIP handles the redundancy automatically\nsol = preprocess_conicIP(Q, c, A, b, cone_dims, G, d; verbose=false)\nsol.status\n\nround.(sol.y, digits=4)","category":"section"},{"location":"installation/#Installation","page":"Installation","title":"Installation","text":"","category":"section"},{"location":"installation/#Requirements","page":"Installation","title":"Requirements","text":"Julia 1.10 or later","category":"section"},{"location":"installation/#Installing-ConicIP.jl","page":"Installation","title":"Installing ConicIP.jl","text":"ConicIP.jl is not yet registered in the Julia General registry. Install it directly from GitHub:\n\nusing Pkg\nPkg.add(url=\"https://github.com/MPF-Optimization-Laboratory/ConicIP.jl\")","category":"section"},{"location":"installation/#Verification","page":"Installation","title":"Verification","text":"After installation, verify that the package loads correctly:\n\nusing ConicIP","category":"section"},{"location":"installation/#Optional:-JuMP-Integration","page":"Installation","title":"Optional: JuMP Integration","text":"To use ConicIP as a JuMP solver, install JuMP as well:\n\nusing Pkg\nPkg.add(\"JuMP\")\n\nThen create a model with:\n\nusing JuMP, ConicIP\nmodel = Model(ConicIP.Optimizer)\n\nSee the JuMP Integration guide for details.","category":"section"},{"location":"tutorials/generated/sdp/#Semidefinite-Programs-(Experimental)","page":"Semidefinite (Experimental)","title":"Semidefinite Programs (Experimental)","text":"warning: Experimental\nSemidefinite cone support in ConicIP is experimental. It works for small problems but has not been extensively tested.\n\nA semidefinite cone constraint requires a symmetric matrix to be positive semidefinite. In ConicIP, matrices are stored in a vectorized form using vecm and mat.","category":"section"},{"location":"tutorials/generated/sdp/#Vectorization-Convention","page":"Semidefinite (Experimental)","title":"Vectorization Convention","text":"The cone specification (\"S\", k) describes a semidefinite cone where k = n(n+1)/2 is the dimension of the vectorized representation of an n × n symmetric matrix.\n\nvecm(Z) vectorizes a symmetric matrix, scaling off-diagonal entries by √2 so that dot(vecm(X), vecm(Y)) == tr(X*Y).\nmat(x) reconstructs the symmetric matrix from its vectorized form.","category":"section"},{"location":"tutorials/generated/sdp/#Example:-Projection-onto-the-PSD-Cone","page":"Semidefinite (Experimental)","title":"Example: Projection onto the PSD Cone","text":"Project the diagonal matrix diag(1, 1, 1, -1, -1, -1) onto the cone of positive semidefinite matrices. The expected result clips the negative eigenvalues to zero: diag(1, 1, 1, 0, 0, 0).\n\nusing ConicIP, SparseArrays, LinearAlgebra\n\n# 6×6 matrix → vectorized dimension k = 6*7/2 = 21\nk = 21\nQ = sparse(1.0I, k, k)\ntarget = diagm(0 => [1.0, 1, 1, -1, -1, -1])\nc = ConicIP.vecm(target)\n\nA = sparse(1.0I, k, k)\nb = zeros(k)\ncone_dims = [(\"S\", k)]\n\nsol = conicIP(Q, c, A, b, cone_dims; verbose=false, optTol=1e-7)\nsol.status\n\nReconstruct the matrix from the solution and check its eigenvalues:\n\nresult = ConicIP.mat(sol.y)\nround.(eigvals(Symmetric(result)), digits=4)\n\nThe negative eigenvalues have been projected to (approximately) zero.","category":"section"},{"location":"tutorials/generated/sdp/#Understanding-vecm-and-mat","page":"Semidefinite (Experimental)","title":"Understanding vecm and mat","text":"Let's see how the vectorization works on a small example:\n\nX = [1.0 2.0 3.0;\n     2.0 5.0 6.0;\n     3.0 6.0 9.0]\n\nv = ConicIP.vecm(X)\n\nThe vector v has length n(n+1)/2 = 6. Off-diagonal entries are scaled by √2:\n\nround.(v, digits=4)\n\nReconstruct the original matrix:\n\nX_recovered = ConicIP.mat(v)\nround.(X_recovered, digits=4)","category":"section"},{"location":"tutorials/generated/socp/#Second-Order-Cone-Programs","page":"Second-Order Cone","title":"Second-Order Cone Programs","text":"A second-order cone (SOC) constraint has the form\n\n‖x‖ ≤ t\n\nor equivalently (t, x) ∈ Q, where Q is the second-order (Lorentz) cone. In ConicIP, this is specified as (\"Q\", dim) where dim = 1 + length(x). The first component of the cone block is the scalar bound t.\n\nSOC constraints appear naturally in robust optimization, norm minimization, and chance-constrained programming.","category":"section"},{"location":"tutorials/generated/socp/#Encoding-SOC-Constraints","page":"Second-Order Cone","title":"Encoding SOC Constraints","text":"To enforce ‖y‖ ≤ t, arrange the constraint rows so that:\n\nRow 1 of the SOC block gives t (the bound)\nRows 2:end give the components of y\n\nConcretely, if Ay - b restricted to the SOC block yields a vector [t; x₁; x₂; ...], then the constraint is ‖[x₁, x₂, ...]‖ ≤ t.","category":"section"},{"location":"tutorials/generated/socp/#Example:-Projection-onto-the-Unit-Ball","page":"Second-Order Cone","title":"Example: Projection onto the Unit Ball","text":"Project a point onto the unit Euclidean ball {y : ‖y‖ ≤ 1}. The expected result is the normalized vector a / ‖a‖.\n\nusing ConicIP, SparseArrays, LinearAlgebra\n\nn = 3\nQ = sparse(1.0I, n, n)\na = ones(n)  # point to project\n\n# SOC constraint: (t, y) ∈ Q with t = 1\n# Encode as: [0ᵀ; I] y - [-1; 0] ∈ Q\n# i.e., the SOC vector is (1, y₁, y₂, y₃) and we need ‖y‖ ≤ 1\nA = [spzeros(1, n); sparse(1.0I, n, n)]\nb = [-1.0; zeros(n)]\ncone_dims = [(\"Q\", n + 1)]\n\nsol = conicIP(Q, Q * a, A, b, cone_dims;\n              verbose=false, optTol=1e-7)\nsol.status\n\nround.(sol.y, digits=4)\n\nCompare to the expected answer a / ‖a‖:\n\nround.(a ./ norm(a), digits=4)","category":"section"},{"location":"tutorials/generated/socp/#Example:-Mixed-Cones-(Nonnegative-SOC)","page":"Second-Order Cone","title":"Example: Mixed Cones (Nonnegative + SOC)","text":"Combine nonnegative (\"R\") and second-order cone (\"Q\") constraints. Here we minimize a linear objective subject to both y ≥ 0 and ‖y‖ ≤ 1:\n\nusing Random\nRandom.seed!(42)\n\nn = 5\nQ = sparse(1.0I, n, n)\nc = randn(n)\n\n# Stack constraints: first n rows are R+ (y ≥ 0),\n# next n+1 rows are SOC (‖y‖ ≤ 1)\nA = [sparse(1.0I, n, n);          # y ≥ 0\n     spzeros(1, n);                # t placeholder for SOC bound\n     sparse(1.0I, n, n)]           # y components in SOC\nb = [zeros(n);                     # R+ bound\n     -1.0;                         # t ≥ 1\n     zeros(n)]                     # SOC body\ncone_dims = [(\"R\", n), (\"Q\", n + 1)]\n\nsol2 = conicIP(Q, c, A, b, cone_dims; verbose=false)\nsol2.status\n\nround.(sol2.y, digits=4)\n\nThe solution lies in the intersection of the nonnegative orthant and the unit ball — the nonnegative part of the unit sphere.","category":"section"},{"location":"tutorials/generated/socp/#Example:-Robust-Least-Squares","page":"Second-Order Cone","title":"Example: Robust Least-Squares","text":"Given an uncertain measurement matrix A₀ + δA and observations b₀, robust least-squares minimizes the worst-case residual:\n\nminimize  ‖A₀ y - b₀‖ + ρ ‖y‖\n\nThis can be reformulated as an SOCP. We introduce auxiliary variables t₁ ≥ ‖A₀ y - b₀‖ and t₂ ≥ ‖y‖ and minimize t₁ + ρ t₂.\n\nRandom.seed!(99)\n\nm, n_var = 10, 5\nA0 = randn(m, n_var)\ny_true = randn(n_var)\nb0 = A0 * y_true + 0.1 * randn(m)\nρ = 0.5  # regularization weight\n\n# Decision variables: [y; t₁; t₂] of length n_var + 2\nnz = n_var + 2\nQz = spzeros(nz, nz)\n\n# Objective: minimize t₁ + ρ t₂  →  c = -[0; 1; ρ] (ConicIP minimizes -c'z)\ncz = zeros(nz)\ncz[n_var+1] = 1.0\ncz[n_var+2] = ρ\n\n# SOC 1: (t₁, A₀ y - b₀) ∈ Q^{m+1}\n#   Row for t₁: [0...0  1  0] z ≥ 0  (extracts t₁)\n#   Rows for residual: [A₀  0  0] z ≥ b₀\nA_soc1_t = spzeros(1, nz); A_soc1_t[1, n_var+1] = 1.0\nA_soc1_r = [sparse(A0) spzeros(m, 2)]\nb_soc1 = [0.0; b0]\n\n# SOC 2: (t₂, y) ∈ Q^{n_var+1}\n#   Row for t₂: [0...0  0  1] z ≥ 0\n#   Rows for y: [I  0  0] z ≥ 0\nA_soc2_t = spzeros(1, nz); A_soc2_t[1, n_var+2] = 1.0\nA_soc2_y = [sparse(1.0I, n_var, n_var) spzeros(n_var, 2)]\nb_soc2 = zeros(1 + n_var)\n\nA_all = [A_soc1_t; A_soc1_r; A_soc2_t; A_soc2_y]\nb_all = [b_soc1; b_soc2]\ncone_dims_robust = [(\"Q\", m + 1), (\"Q\", n_var + 1)]\n\nsol3 = conicIP(Qz, cz, sparse(A_all), b_all, cone_dims_robust; verbose=false)\nsol3.status\n\nThe robust solution:\n\nround.(sol3.y[1:n_var], digits=4)","category":"section"},{"location":"tutorials/generated/qp/#Quadratic-Programs","page":"Quadratic Programs","title":"Quadratic Programs","text":"A quadratic program (QP) has a positive semidefinite Hessian Q:\n\nminimize    ½ yᵀQy - cᵀy\nsubject to   Ay ≥ b\n             Gy  = d","category":"section"},{"location":"tutorials/generated/qp/#Example:-Projection-onto-the-Simplex","page":"Quadratic Programs","title":"Example: Projection onto the Simplex","text":"Project the point p = [1, 2, 3, 4, 5] onto the probability simplex {y : y ≥ 0, ∑yᵢ = 1}. This is equivalent to solving minimize ½ ‖y - p‖² subject to y ≥ 0, 1ᵀy = 1, which in ConicIP form becomes minimize ½ yᵀIy - pᵀy with appropriate constraints.\n\nusing ConicIP, SparseArrays, LinearAlgebra\n\nn = 5\nQ = sparse(1.0I, n, n)\np = collect(1.0:n)\n\n# Nonnegativity constraints: y ≥ 0\nA = sparse(1.0I, n, n)\nb = zeros(n)\ncone_dims = [(\"R\", n)]\n\n# Simplex constraint: sum(y) = 1\nG = ones(1, n)\nd = [1.0]\n\n# Note: we pass Q*p as the linear term c = Qp = Ip = p\nsol = conicIP(Q, Q * p, A, b, cone_dims, G, d;\n              verbose=false, optTol=1e-7)\nsol.status\n\nround.(sol.y, digits=4)\n\nThe solution concentrates weight on the largest components of p, as expected for the nearest point on the simplex.","category":"section"},{"location":"tutorials/generated/qp/#Convergence-Diagnostics","page":"Quadratic Programs","title":"Convergence Diagnostics","text":"The Solution struct reports convergence diagnostics:\n\nprFeas – primal feasibility residual\nduFeas – dual feasibility (KKT stationarity) residual\nmuFeas – complementarity residual\npobj, dobj – primal and dual objective values\n\n(prFeas=sol.prFeas, duFeas=sol.duFeas, muFeas=sol.muFeas,\n pobj=round(sol.pobj, digits=6), dobj=round(sol.dobj, digits=6))\n\nAt optimality, pobj ≈ dobj and all residuals are below optTol.","category":"section"},{"location":"tutorials/generated/qp/#Example:-Portfolio-Optimization","page":"Quadratic Programs","title":"Example: Portfolio Optimization","text":"A classic application of QP is mean-variance portfolio optimization. Given expected returns μ and a covariance matrix Σ, find the minimum-variance portfolio with expected return at least r_min:\n\nminimize    ½ yᵀΣy\nsubject to  μᵀy ≥ r_min\n            1ᵀy = 1\n            y ≥ 0\n\nusing Random\nRandom.seed!(42)\n\nnassets = 8\nreturns = rand(nassets) * 0.1          # expected returns: 0% to 10%\n# Build a realistic covariance matrix from factor model\nF = randn(nassets, 3) * 0.05\nSigma = F * F' + Diagonal(rand(nassets) * 0.01 .+ 0.001)\nSigma = sparse(Symmetric(Sigma))\n\nr_min = 0.05  # target minimum return\n\n# Q = Sigma, c = 0 (pure quadratic objective)\nQ_port = Sigma\nc_port = zeros(nassets)\n\n# Inequality constraints: [μᵀ; I] y ≥ [r_min; 0]\nA_port = sparse([returns'; I(nassets)])\nb_port = [r_min; zeros(nassets)]\ncone_dims_port = [(\"R\", 1 + nassets)]\n\n# Equality constraint: sum(y) = 1\nG_port = ones(1, nassets)\nd_port = [1.0]\n\nsol_port = conicIP(Q_port, c_port, A_port, b_port, cone_dims_port,\n                   G_port, d_port; verbose=false, optTol=1e-7)\nsol_port.status\n\nweights = round.(sol_port.y, digits=4)\n\nPortfolio expected return and variance:\n\nport_return = round(dot(returns, sol_port.y), digits=6)\nport_variance = round((sol_port.y' * Sigma * sol_port.y)[1], digits=6)\n(expected_return=port_return, variance=port_variance)","category":"section"},{"location":"guides/kkt_solvers/#KKT-Solvers","page":"KKT Solvers","title":"KKT Solvers","text":"At each interior-point iteration, ConicIP solves a 3×3 block KKT system. The choice of solver for this system has a significant impact on performance. This guide covers the built-in solvers, when to use each, and how to write custom solvers.","category":"section"},{"location":"guides/kkt_solvers/#The-KKT-System","page":"KKT Solvers","title":"The KKT System","text":"The system solved at each iteration is:\n\n┌             ┐ ┌   ┐   ┌   ┐\n│ Q   G'  -A' │ │ a │   │ x │\n│ G           │ │ b │ = │ y │\n│ A       FᵀF │ │ c │   │ z │\n└             ┘ └   ┘   └   ┘\n\nwhere F is a Block diagonal matrix representing the Nesterov-Todd scaling. The block type depends on the cone:\n\nCone Block type Description\n\"R\" Diagonal Diagonal scaling for nonnegative orthant\n\"Q\" SymWoodbury Low-rank-plus-diagonal for second-order cone\n\"S\" VecCongurance Congruence transform for semidefinite cone","category":"section"},{"location":"guides/kkt_solvers/#Built-in-Solvers","page":"KKT Solvers","title":"Built-in Solvers","text":"","category":"section"},{"location":"guides/kkt_solvers/#kktsolver_qr-(default)","page":"KKT Solvers","title":"kktsolver_qr (default)","text":"QR-based solver using the double QR method from CVXOPT. This is the default and works reliably for all problem types.\n\nWhen to use: General-purpose; a safe default for any problem.\n\nTrade-offs: More numerically robust than sparse LU, but slower for large sparse problems.","category":"section"},{"location":"guides/kkt_solvers/#kktsolver_sparse","page":"KKT Solvers","title":"kktsolver_sparse","text":"Sparse LU solver that intelligently chooses between two internal strategies:\n\nLifted formulation: Replaces large diagonal-plus-low-rank blocks with lifted variables, keeping the system sparse. Better for large second-order cones.\nDense formulation: Converts all scaling blocks to dense matrices. Better when constraints are the product of many small cones.\n\nThe solver estimates the nonzero count for each strategy and picks the sparser one automatically.\n\nWhen to use: Large problems with sparse Q and A.\n\nsol = conicIP(Q, c, A, b, cone_dims; kktsolver=kktsolver_sparse)","category":"section"},{"location":"guides/kkt_solvers/#kktsolver_2x2-(with-pivot)","page":"KKT Solvers","title":"kktsolver_2x2 (with pivot)","text":"A 2×2 sparse LU solver that works on the Schur complement system obtained by pivoting on the third block. Must be wrapped with pivot:\n\nsol = conicIP(Q, c, A, b, cone_dims; kktsolver=pivot(kktsolver_2x2))\n\nWhen to use: Problems where the Schur complement Q + Aᵀ(FᵀF)⁻¹A is sparser or better conditioned than the full 3×3 system.","category":"section"},{"location":"guides/kkt_solvers/#Choosing-a-Solver","page":"KKT Solvers","title":"Choosing a Solver","text":"Problem characteristics Recommended solver\nSmall/medium, any structure kktsolver_qr (default)\nLarge, sparse Q and A kktsolver_sparse\nLarge, few large SOC cones kktsolver_sparse (uses lifted form)\nLarge, many small cones kktsolver_sparse (uses dense form)\nStructured Schur complement pivot(kktsolver_2x2)\nCustom problem structure Write a custom solver (see below)","category":"section"},{"location":"guides/kkt_solvers/#Writing-a-Custom-Solver","page":"KKT Solvers","title":"Writing a Custom Solver","text":"A custom KKT solver is a three-level nested function:\n\nfunction my_kktsolver(Q, A, G, cone_dims)\n    # Level 1: One-time setup (symbolic factorization, preallocation)\n    # Called once before the solve loop.\n\n    function solve3x3gen(F, F⁻ᵀ)\n        # Level 2: Per-iteration setup (F changes each iteration)\n        # Compute numeric factorization using current scaling F.\n\n        function solve3x3(x, y, z)\n            # Level 3: Solve the 3×3 system given RHS (x, y, z).\n            # Return (a, b, c) where:\n            #   Qa + G'b - A'c = x\n            #   Ga = y\n            #   Aa + FᵀFc = z\n            return (a, b, c)\n        end\n        return solve3x3\n    end\n    return solve3x3gen\nend\n\nPass it to the solver via the kktsolver keyword:\n\nsol = conicIP(Q, c, A, b, cone_dims; kktsolver=my_kktsolver)","category":"section"},{"location":"guides/kkt_solvers/#Example:-Diagonal-QP","page":"KKT Solvers","title":"Example: Diagonal QP","text":"For minimize ½ xᵀQx - cᵀx subject to x ≥ 0 with diagonal Q, the KKT system simplifies (no equality constraints, G is empty) to:\n\n┌            ┐ ┌   ┐   ┌   ┐\n│ Q       -I │ │ a │   │ x │\n│ I    FᵀF   │ │ c │ = │ z │\n└            ┘ └   ┘   └   ┘\n\nSince F is Diagonal for \"R\" cones, pivoting on the second block gives (Q + (FᵀF)⁻¹) a = x + (FᵀF)⁻¹ z, solvable by Cholesky:\n\nusing ConicIP, SparseArrays, LinearAlgebra, Random\nRandom.seed!(42)\n\nn = 50\nQ = sprandn(n, n, 0.3); Q = Q'Q + 0.1I  # make positive definite\nc = ones(n)\nA = sparse(1.0I, n, n)\nb = zeros(n)\ncone_dims = [(\"R\", n)]\n\nfunction my_kktsolver(Q, A, G, cone_dims)\n    function solve3x3gen(F, F⁻ᵀ)\n        invFᵀF = inv(F'F)\n        QpD = cholesky(Q + spdiagm(0 => (F[1].diag).^(-2)))\n\n        function solve3x3(x, y, z)\n            a = QpD \\ (x + A' * (invFᵀF * z))\n            c = invFᵀF * (z - A * a)\n            b = zeros(0)\n            return (a, b, c)\n        end\n    end\nend\n\nsol = conicIP(Q, c, A, b, cone_dims; kktsolver=my_kktsolver, verbose=false)\nsol.status","category":"section"},{"location":"guides/kkt_solvers/#The-pivot-Wrapper","page":"KKT Solvers","title":"The pivot Wrapper","text":"The pattern of reducing a 3×3 system to 2×2 by pivoting on the third block is common enough that ConicIP provides pivot to automate it.\n\nA 2×2 solver has the signature:\n\nfunction my_2x2_solver(Q, A, G, cone_dims)\n    function solve2x2gen(F, F⁻ᵀ)\n        # Build and factor the Schur complement: Q + Aᵀ(FᵀF)⁻¹A\n        function solve2x2(y, w)\n            # Solve for (Δy, Δw) and return them\n            return (Δy, Δw)\n        end\n        return solve2x2\n    end\n    return solve2x2gen\nend\n\nThen pivot(my_2x2_solver) produces a valid 3×3 solver. Here's the same diagonal QP using pivot:\n\nfunction my_2x2_solver(Q, A, G, cone_dims)\n    function solve2x2gen(F, F⁻ᵀ)\n        QpD = cholesky(Q + spdiagm(0 => (F[1].diag).^(-2)))\n        return (y, w) -> (QpD \\ y, zeros(0))\n    end\nend\n\nsol2 = conicIP(Q, c, A, b, cone_dims;\n               kktsolver=pivot(my_2x2_solver), verbose=false)\nsol2.status","category":"section"},{"location":"guides/kkt_solvers/#Performance-Tips","page":"KKT Solvers","title":"Performance Tips","text":"Preallocate buffers in level 1 (the outer function) and reuse them in levels 2 and 3.\nReuse symbolic factorizations when the sparsity pattern doesn't change between iterations (only the numeric values of F change).\nAvoid inv(F'F) for large blocks — compute the action of (FᵀF)⁻¹ on a vector instead.\nFor problems with a callback.ipynb example, see the examples/ directory in the repository.","category":"section"},{"location":"tutorials/generated/getting_started/#Getting-Started","page":"Getting Started","title":"Getting Started","text":"This tutorial introduces ConicIP.jl's problem formulation, core API, and solution interpretation. By the end you will have solved your first optimization problem in under a minute.","category":"section"},{"location":"tutorials/generated/getting_started/#Problem-Formulation","page":"Getting Started","title":"Problem Formulation","text":"ConicIP solves optimization problems of the form\n\nminimize    ½ yᵀQy - cᵀy\nsubject to  Ay ≥_K b\n            Gy  = d\n\nwhere ≥_K denotes a generalized inequality with respect to a cone K.","category":"section"},{"location":"tutorials/generated/getting_started/#Arguments-at-a-Glance","page":"Getting Started","title":"Arguments at a Glance","text":"Argument Size Description\nQ n × n Positive semidefinite Hessian (use spzeros(n,n) for LPs)\nc n Linear objective term (vector)\nA m × n Inequality constraint matrix\nb m Inequality right-hand side (vector)\ncone_dims Vector of (String,Int) Cone specification for rows of A\nG p × n Equality constraint matrix (optional)\nd p Equality right-hand side (vector, optional)","category":"section"},{"location":"tutorials/generated/getting_started/#Cone-Specification","page":"Getting Started","title":"Cone Specification","text":"The cone_dims argument is a vector of (type, dimension) tuples describing how the rows of A and b are partitioned into cone constraints:\n\n(\"R\", n) – nonnegative orthant: the first n rows satisfy Ay - b ≥ 0\n(\"Q\", m) – second-order cone: the next m rows satisfy ‖(Ay-b)[2:end]‖ ≤ (Ay-b)[1]\n(\"S\", k) – semidefinite cone (experimental): the next k rows represent a vectorized symmetric matrix that must be positive semidefinite, where k = n(n+1)/2\n\nFor example, [(\"R\", 3), (\"Q\", 5)] means the first 3 rows of Ay ≥ b are nonnegative constraints, and the next 5 rows form a second-order cone constraint.","category":"section"},{"location":"tutorials/generated/getting_started/#Example:-Box-Constrained-QP","page":"Getting Started","title":"Example: Box-Constrained QP","text":"Let's solve a box-constrained quadratic program: minimize ½ yᵀQy - cᵀy subject to 0 ≤ y ≤ 1.\n\nWe encode the box constraints 0 ≤ y ≤ 1 as [I; -I] y ≥ [0; -1].\n\nusing ConicIP, SparseArrays, LinearAlgebra, Random\nRandom.seed!(42)\n\nn = 10\nQ = sparse(Diagonal(rand(n) .+ 0.1))\nc = randn(n)\n\n# Encode 0 ≤ y ≤ 1 as [I; -I] y ≥ [0; -1]\nA = sparse([I(n); -I(n)])\nb = [zeros(n); -ones(n)]\ncone_dims = [(\"R\", 2n)]\n\nsol = conicIP(Q, c, A, b, cone_dims; verbose=false)\nsol.status\n\nThe primal solution:\n\nround.(sol.y, digits=4)","category":"section"},{"location":"tutorials/generated/getting_started/#Interpreting-the-Solution","page":"Getting Started","title":"Interpreting the Solution","text":"The solver returns a Solution struct with these key fields:\n\nField Description\nsol.y Primal variables (vector)\nsol.v Dual variables for inequality constraints\nsol.w Dual variables for equality constraints\nsol.status :Optimal, :Infeasible, :Unbounded, :Abandoned, or :Error\nsol.pobj, sol.dobj Primal and dual objective values\nsol.prFeas Primal feasibility residual\nsol.duFeas Dual feasibility residual\nsol.muFeas Complementarity residual\nsol.Iter Number of iterations\n\nLet's inspect the convergence residuals:\n\n(prFeas=sol.prFeas, duFeas=sol.duFeas, muFeas=sol.muFeas)\n\nAll residuals are well below the default tolerance (optTol = 1e-6).","category":"section"},{"location":"tutorials/generated/getting_started/#Using-JuMP-Instead","page":"Getting Started","title":"Using JuMP Instead","text":"You can also model problems via JuMP instead of the direct conicIP API. Here's the same box-constrained QP:\n\nusing JuMP\n\nmodel = Model(() -> ConicIP.Optimizer(verbose=false))\n\n@variable(model, 0 <= x[i=1:n] <= 1)\n@objective(model, Min, 0.5 * sum(Q[i,i] * x[i]^2 for i in 1:n) - sum(c[i] * x[i] for i in 1:n))\n\noptimize!(model)\ntermination_status(model)\n\n<br>\n\nThe JuMP solution matches the direct API:\n\nround.(value.(x), digits=4)","category":"section"},{"location":"tutorials/generated/getting_started/#Next-Steps","page":"Getting Started","title":"Next Steps","text":"Linear Programs – LPs with equality constraints and duals\nQuadratic Programs – portfolio optimization on the simplex\nSecond-Order Cone Programs – norm minimization and mixed cones\nJuMP Integration – full guide on using ConicIP through JuMP","category":"section"},{"location":"api/#API-Reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"api/#Solver","page":"API Reference","title":"Solver","text":"The main entry point for solving conic optimization problems.","category":"section"},{"location":"api/#Solution","page":"API Reference","title":"Solution","text":"The solver returns a Solution struct containing primal/dual variables, status, and convergence information.\n\nKey fields:\n\nField Type Description\ny Matrix Primal variables\nw Matrix Dual variables for equality constraints (Gy = d)\nv Matrix Dual variables for inequality constraints (Ay ≥ b)\nstatus Symbol Termination status (see below)\npobj Real Primal objective value\ndobj Real Dual objective value\nprFeas Real Primal feasibility residual\nduFeas Real Dual feasibility residual\nmuFeas Real Complementarity residual\nIter Integer Number of iterations\nMu Real Final barrier parameter\n\nStatus values:\n\nStatus Meaning\n:Optimal Converged to an optimal solution\n:Infeasible Problem is primal infeasible (dual certificate found)\n:Unbounded Problem is dual infeasible / primal unbounded\n:Abandoned Solver stalled (step size too small or numerical issues)\n:Error Solver encountered an error\n\nSee Troubleshooting Solver Output in the Mathematical Background for guidance on non-optimal statuses.","category":"section"},{"location":"api/#JuMP-/-MathOptInterface","page":"API Reference","title":"JuMP / MathOptInterface","text":"","category":"section"},{"location":"api/#KKT-Solver-Functions","page":"API Reference","title":"KKT Solver Functions","text":"Three built-in KKT solvers are provided. See the KKT Solvers guide for detailed usage and custom solver development.","category":"section"},{"location":"api/#Block-Diagonal-Matrices","page":"API Reference","title":"Block Diagonal Matrices","text":"The Nesterov-Todd scaling matrix is represented as a block diagonal matrix where each block corresponds to a cone in the cone specification.","category":"section"},{"location":"api/#Utilities","page":"API Reference","title":"Utilities","text":"","category":"section"},{"location":"api/#Internal","page":"API Reference","title":"Internal","text":"These functions are implementation details and not part of the public API.","category":"section"},{"location":"api/#ConicIP.conicIP","page":"API Reference","title":"ConicIP.conicIP","text":"conicIP(Q, c, A, b, conedims, G, d;   solve3x3gen = solve3x3gensparse,   optTol = 1e-5,   DTB = 0.01,   verbose = true,   maxRefinementSteps = 3,   maxIters = 100,   cache_nestodd = false,   refinementThreshold = optTol/1e7)\n\nInterior point solver for the system\n\nminimize    ½yᵀQy - cᵀy\ns.t         Ay >= b\n            Gy  = d\n\nc, b, d are vectors (or any AbstractVector)\n\ncone_dims is an array of tuples (Cone Type, Dimension)\n\ne.g. [(\"R\",2),(\"Q\",4)] means\n(y₁, y₂)          in  R+\n(y₃, y₄, y₅, y₆)  in  Q\n\nSDP Cones are NOT supported and purely experimental at this point.\n\nThe parameter solve3x3gen allows the passing of a custom solver for the KKT System, as follows\n\njulia> L = solve3x3gen(F,F⁻ᵀ,Q,A,G)\n\nThen this\n\njulia> (a,b,c) = L(y,w,v)\n\nsolves the system\n┌             ┐ ┌   ┐   ┌   ┐\n│ Q   G'  -A' │ │ a │ = │ y │\n│ G           │ │ b │   │ w │\n│ A       FᵀF │ │ c │   │ v │\n└             ┘ └   ┘   └   ┘\n\nWe can also wrap a 2x2 solver using pivot3gen(solve2x2gen) The 2x2 solves the system\n\njulia> L = solve2x2gen(F,F⁻ᵀ,Q,A,G)\n\nThen this\n\njulia> (a,b) = L(y,w)\n\nsolves the system\n\n┌                     ┐ ┌   ┐   ┌   ┐\n│ Q + Aᵀinv(FᵀF)A  G' │ │ a │ = │ y │\n│ G                   │ │ b │   │ w │\n└                     ┘ └   ┘   └   ┘\n\n\n\n\n\n","category":"function"},{"location":"api/#ConicIP.preprocess_conicIP","page":"API Reference","title":"ConicIP.preprocess_conicIP","text":"ConicIP with preprocessing to ensure the following rank constraints\n\nPrimal equailty constraints : Gx = d Rank condition              : rank(G) = size(G,1)\n\nDual equality constraints   : [ Q A' G'] = c Rank condition              : rank([Q A' G']) = size(Q,1)\n\n\n\n\n\n","category":"function"},{"location":"api/#ConicIP.Solution","page":"API Reference","title":"ConicIP.Solution","text":"Solution\n\nReturn type of conicIP and preprocess_conicIP.\n\nFields\n\ny::Vector{Float64} – primal variables\nw::Vector{Float64} – dual variables for equality constraints (Gy = d)\nv::Vector{Float64} – dual variables for inequality constraints (Ay ≥_K b)\nstatus::Symbol – :Optimal, :Infeasible, :Unbounded, :Abandoned, or :Error\nIter::Integer – number of interior-point iterations\nMu::Real – final complementarity gap parameter\nprFeas::Real – primal feasibility residual\nduFeas::Real – dual feasibility residual\nmuFeas::Real – complementarity residual\npobj::Real – primal objective value\ndobj::Real – dual objective value\n\n\n\n\n\n","category":"type"},{"location":"api/#ConicIP.Optimizer","page":"API Reference","title":"ConicIP.Optimizer","text":"Optimizer(; verbose=false, optTol=1e-6, maxIters=100)\n\nMathOptInterface optimizer wrapping the ConicIP interior-point solver. Use as a JuMP solver via Model(ConicIP.Optimizer).\n\nKeyword Arguments\n\nverbose::Bool – print solver iterations (default: false)\noptTol::Float64 – optimality tolerance (default: 1e-6)\nmaxIters::Int – maximum iterations (default: 100)\n\nSupported Constraints\n\nVector: Zeros, Nonnegatives, Nonpositives, SecondOrderCone, PositiveSemidefiniteConeTriangle\nScalar: EqualTo, GreaterThan, LessThan\n\n\n\n\n\n","category":"type"},{"location":"api/#ConicIP.kktsolver_qr","page":"API Reference","title":"ConicIP.kktsolver_qr","text":"Solves the 3x3 system\n\n┌             ┐ ┌    ┐   ┌   ┐\n│ Q   G'  -A' │ │ y' │ = │ y │\n│ G           │ │ w' │   │ w │\n│ A       FᵀF │ │ v' │   │ v │\n└             ┘ └    ┘   └   ┘\n\nby the double QR method described in CVXOPT http://www.seas.ucla.edu/~vandenbe/publications/coneprog.pdf section 10.2\n\n\n\n\n\n","category":"function"},{"location":"api/#ConicIP.kktsolver_sparse","page":"API Reference","title":"ConicIP.kktsolver_sparse","text":"Solves the 3x3 system\n\n┌             ┐ ┌    ┐   ┌   ┐\n│ Q   G'  -A' │ │ y' │ = │ y │\n│ G           │ │ w' │   │ w │\n│ A       FᵀF │ │ v' │   │ v │\n└             ┘ └    ┘   └   ┘\n\nBy lifting the large diagonal plus rank 3 blocks of FᵀF\n\nIntelligently chooses between solve3x3gensparselift and solve3x3gensparsedense by approximating the number of non-zeros in both and choosing the form with more sparsity. The former is better for large second order cones, while the latter is better if the constraints are the product of many small cones.\n\n\n\n\n\n","category":"function"},{"location":"api/#ConicIP.kktsolver_2x2","page":"API Reference","title":"ConicIP.kktsolver_2x2","text":"Solves the 2x2 system\n\n┌                   ┐ ┌    ┐   ┌   ┐\n│ Q + A'F⁻¹F⁻ᵀA  G' │ │ y' │ = │ y │\n│ G                 │ │ w' │   │ w │\n└                   ┘ └    ┘   └   ┘\n\n\n\n\n\n","category":"function"},{"location":"api/#ConicIP.pivot","page":"API Reference","title":"ConicIP.pivot","text":"pivot(kktsolver_2x2)\n\nWrap a 2-by-2 KKT solver into a 3-by-3 solver by pivoting on the third component. The inner solver handles the Schur complement system; pivot reconstructs the full solution.\n\nSee also conicIP for the KKT solver interface specification.\n\n\n\n\n\n","category":"function"},{"location":"api/#ConicIP.Block","page":"API Reference","title":"ConicIP.Block","text":"Block(size::Int)\nBlock(Blk::Vector)\n\nBlock diagonal matrix type. Each diagonal block can be a different matrix type (Diagonal, SymWoodbury, VecCongurance, or dense Matrix).\n\nUsed internally to represent the Nesterov-Todd scaling matrix, where each block corresponds to a cone in the cone specification.\n\nSupports arithmetic (*, +, -, inv, adjoint, ^), conversion to sparse and Matrix, and block-wise function application via broadcastf.\n\nIndexing\n\nB[i] returns the i-th diagonal block\nB[i] = M sets the i-th diagonal block\n\n\n\n\n\n","category":"type"},{"location":"api/#ConicIP.block_idx","page":"API Reference","title":"ConicIP.block_idx","text":"block_idx(A::Block)\n\nReturn a vector of UnitRange{Int} giving the row/column index ranges for each diagonal block of A.\n\n\n\n\n\n","category":"function"},{"location":"api/#ConicIP.broadcastf","page":"API Reference","title":"ConicIP.broadcastf","text":"broadcastf(op, A::Block)\nbroadcastf(op, A::Block, B::Block)\nbroadcastf(op, A::Block, x::Union{Vector,Matrix})\n\nApply function op block-wise to the diagonal blocks of A (and optionally B or the corresponding segments of x).\n\n\n\n\n\n","category":"function"},{"location":"api/#ConicIP.Id","page":"API Reference","title":"ConicIP.Id","text":"Id(n)\n\nCreate an n-by-n identity matrix as Diagonal(ones(n)).\n\n\n\n\n\n","category":"function"},{"location":"api/#ConicIP.VecCongurance","page":"API Reference","title":"ConicIP.VecCongurance","text":"VecCongurance(R)\n\nLinear operator representing a congruence transform in vectorized form. The action W * x computes vecm(R' * mat(x) * R).\n\nUsed internally as the Nesterov-Todd scaling matrix for semidefinite cones.\n\n\n\n\n\n","category":"type"},{"location":"api/#ConicIP.mat","page":"API Reference","title":"ConicIP.mat","text":"mat(x)\n\nConvert a vectorized symmetric matrix (scaled lower-triangular form) back to a full symmetric matrix. Inverse of vecm.\n\n\n\n\n\n","category":"function"},{"location":"api/#ConicIP.vecm","page":"API Reference","title":"ConicIP.vecm","text":"vecm(Z)\n\nVectorize a symmetric matrix Z into scaled lower-triangular form. Off-diagonal entries are scaled by √2 so that dot(vecm(X), vecm(Y)) == tr(X*Y). Inverse of mat.\n\n\n\n\n\n","category":"function"},{"location":"api/#ConicIP.imcols","page":"API Reference","title":"ConicIP.imcols","text":"imcols(A, b; ϵ = 1e-10)\n\nRemoves redundant inequalities in a system of equations\n\nAx = b\n\nand checks if the equations are consistent.\n\n\n\n\n\n","category":"function"},{"location":"api/#ConicIP.inv_adjoint!","page":"API Reference","title":"ConicIP.inv_adjoint!","text":"inv_adjoint!(dest::Block, src::Block)\n\nCompute adjoint(inv(src)) block-wise, reusing the dest Block shell. Avoids allocating two intermediate Blocks for inv(F)'.\n\n\n\n\n\n","category":"function"},{"location":"api/#ConicIP.pivotgen","page":"API Reference","title":"ConicIP.pivotgen","text":"Wrapper around solve2xegen to solve 3x3 systems by pivoting on the third component.\n\n\n\n\n\n","category":"function"},{"location":"api/#ConicIP.placeholder","page":"API Reference","title":"ConicIP.placeholder","text":"Creates a matrix with the same sparsity structure as F\n\n\n\n\n\n","category":"function"},{"location":"api/#ConicIP.identical_sparse_structure","page":"API Reference","title":"ConicIP.identical_sparse_structure","text":"Checks if two sparse matrices have the same sparse structure\n\n\n\n\n\n","category":"function"},{"location":"api/#ConicIP.count_lift","page":"API Reference","title":"ConicIP.count_lift","text":"Estimates for the number of nonzeros of lift(F)\n\n\n\n\n\n","category":"function"},{"location":"api/#ConicIP.count_dense","page":"API Reference","title":"ConicIP.count_dense","text":"Estimates the number of nonzeros of F\n\n\n\n\n\n","category":"function"},{"location":"tutorials/generated/lp/#Linear-Programs","page":"Linear Programs","title":"Linear Programs","text":"A linear program (LP) is a special case of the ConicIP problem formulation with Q = 0:\n\nminimize    -cᵀy\nsubject to   Ay ≥ b\n             Gy  = d","category":"section"},{"location":"tutorials/generated/lp/#Example:-LP-with-Equality-and-Inequality-Constraints","page":"Linear Programs","title":"Example: LP with Equality and Inequality Constraints","text":"Solve a small LP with nonnegativity and an equality constraint:\n\nminimize    -2y₁ - 3y₂ - y₃ - y₄ - y₅\nsubject to   y₁ + y₂ + y₃ + y₄ + y₅ = 4\n             y ≥ 0\n\nusing ConicIP, SparseArrays, LinearAlgebra\n\nn = 5\nQ = spzeros(n, n)\nc = [2.0, 3.0, 1.0, 1.0, 1.0]\n\n# Nonnegativity: y ≥ 0\nA = sparse(1.0I, n, n)\nb = zeros(n)\ncone_dims = [(\"R\", n)]\n\n# Equality constraint: sum(y) = 4\nG = ones(1, n)\nd = [4.0]\n\nsol = conicIP(Q, c, A, b, cone_dims, G, d; verbose=false)\nsol.status\n\nround.(sol.y, digits=4)\n\nThe optimal solution puts all weight on the variable with the largest objective coefficient (y₂ = 4).","category":"section"},{"location":"tutorials/generated/lp/#Reading-Dual-Variables","page":"Linear Programs","title":"Reading Dual Variables","text":"The dual variables sol.v give the shadow prices for the inequality constraints. Each component of v corresponds to one row of A y ≥ b.\n\nround.(sol.v, digits=4)\n\nThe dual variable for the equality constraint is in sol.w:\n\nround.(sol.w, digits=4)","category":"section"},{"location":"tutorials/generated/lp/#Verifying-Optimality","page":"Linear Programs","title":"Verifying Optimality","text":"At optimality, the primal and dual objectives should match:\n\n(pobj=round(sol.pobj, digits=6), dobj=round(sol.dobj, digits=6))\n\nAnd all feasibility residuals should be small:\n\n(prFeas=sol.prFeas, duFeas=sol.duFeas, muFeas=sol.muFeas)","category":"section"},{"location":"tutorials/generated/lp/#A-Larger-Example:-Transportation-Problem","page":"Linear Programs","title":"A Larger Example: Transportation Problem","text":"Consider a transportation problem with 3 supply nodes and 4 demand nodes. The cost of shipping one unit from supply node i to demand node j is cost[i,j]. We want to minimize total shipping cost subject to supply and demand constraints.\n\nusing Random\nRandom.seed!(123)\n\nnsupply, ndemand = 3, 4\ncost = rand(nsupply, ndemand) .+ 0.1\n\n# Decision variables: x[i,j] = amount shipped from i to j\nnvar = nsupply * ndemand\nQ = spzeros(nvar, nvar)\nc = vec(cost)                   # minimize (note: conicIP minimizes -c'y, so negate)\nc = -c                           # we want to minimize cost'y, so set c = -cost\n\n# Nonnegativity\nA = sparse(1.0I, nvar, nvar)\nb_ineq = zeros(nvar)\ncone_dims = [(\"R\", nvar)]\n\n# Supply constraints: sum_j x[i,j] = supply[i]\n# Demand constraints: sum_i x[i,j] = demand[j]\nsupply = [10.0, 15.0, 20.0]\ndemand = [8.0, 12.0, 10.0, 15.0]  # sum(demand) = sum(supply) = 45\n\nG_supply = zeros(nsupply, nvar)\nfor i in 1:nsupply\n    for j in 1:ndemand\n        G_supply[i, (i-1)*ndemand + j] = 1.0\n    end\nend\n\nG_demand = zeros(ndemand, nvar)\nfor j in 1:ndemand\n    for i in 1:nsupply\n        G_demand[j, (i-1)*ndemand + j] = 1.0\n    end\nend\n\nG = [G_supply; G_demand]\nd = [supply; demand]\n\nsol2 = conicIP(Q, c, A, b_ineq, cone_dims, G, d; verbose=false)\nsol2.status\n\nThe optimal shipping plan:\n\nshipments = reshape(round.(sol2.y, digits=2), nsupply, ndemand)","category":"section"},{"location":"guides/jump/#JuMP-Integration","page":"JuMP Integration","title":"JuMP Integration","text":"ConicIP provides a MathOptInterface wrapper, so it can be used as a solver backend for JuMP.","category":"section"},{"location":"guides/jump/#Setup","page":"JuMP Integration","title":"Setup","text":"using JuMP, ConicIP\nmodel = Model(ConicIP.Optimizer)","category":"section"},{"location":"guides/jump/#Solver-Options","page":"JuMP Integration","title":"Solver Options","text":"Pass options at construction via an anonymous function:\n\nmodel = Model(() -> ConicIP.Optimizer(verbose=false, optTol=1e-8, maxIters=200))\n\nThe available options are:\n\nOption Type Default Description\nverbose Bool false Print solver iterations\noptTol Float64 1e-6 Optimality tolerance\nmaxIters Int 100 Maximum iterations","category":"section"},{"location":"guides/jump/#Example:-Simple-LP","page":"JuMP Integration","title":"Example: Simple LP","text":"using JuMP, ConicIP\n\nmodel = Model(() -> ConicIP.Optimizer(verbose=false, optTol=1e-6))\n\n@variable(model, x[1:2] >= 0)\n@objective(model, Min, x[1] + x[2])\n@constraint(model, x[1] + x[2] >= 1)\n\noptimize!(model)\ntermination_status(model)\n\nround(objective_value(model), digits=6)","category":"section"},{"location":"guides/jump/#Example:-SOC-Constraint","page":"JuMP Integration","title":"Example: SOC Constraint","text":"using JuMP, ConicIP\n\nmodel = Model(() -> ConicIP.Optimizer(verbose=false, optTol=1e-6))\n\n@variable(model, x[1:2])\n@variable(model, t)\n@objective(model, Min, t)\n@constraint(model, x[1] == 1)\n@constraint(model, x[2] == 1)\n@constraint(model, [t; x] in SecondOrderCone())\n\noptimize!(model)\ntermination_status(model)\n\nThe minimum norm is √2:\n\nround(objective_value(model), digits=4)","category":"section"},{"location":"guides/jump/#Example:-Maximization","page":"JuMP Integration","title":"Example: Maximization","text":"using JuMP, ConicIP\n\nmodel = Model(() -> ConicIP.Optimizer(verbose=false, optTol=1e-6))\n\n@variable(model, x[1:2] >= 0)\n@objective(model, Max, x[1] + 2x[2])\n@constraint(model, x[1] + x[2] <= 1)\n\noptimize!(model)\ntermination_status(model)\n\nround(objective_value(model), digits=6)","category":"section"},{"location":"guides/jump/#Supported-Constraints","page":"JuMP Integration","title":"Supported Constraints","text":"Constraint type JuMP syntax\nNonnegative @variable(model, x >= 0) or @constraint(model, x in MOI.Nonnegatives(n))\nNonpositive @constraint(model, x in MOI.Nonpositives(n))\nZero (equality) @constraint(model, x .== 0) or @constraint(model, x in MOI.Zeros(n))\nSecond-order cone @constraint(model, [t; x] in SecondOrderCone())\nPSD (experimental) @constraint(model, X in PSDCone())\nScalar equal @constraint(model, x == 1)\nScalar greater @constraint(model, x >= 1)\nScalar less @constraint(model, x <= 1)","category":"section"},{"location":"guides/jump/#Limitations","page":"JuMP Integration","title":"Limitations","text":"warning: No quadratic objectives through JuMP\nThe MOI wrapper currently supports only linear objectives. For quadratic programs, use the direct conicIP interface.\n\nOther limitations:\n\nNo integer variables\nNo indicator or SOS constraints\nSemidefinite support is experimental","category":"section"},{"location":"background/#Mathematical-Background","page":"Mathematical Background","title":"Mathematical Background","text":"This page provides the mathematical context needed to understand ConicIP's behavior, interpret its output, and tune its parameters. For full derivations, see the references at the end.","category":"section"},{"location":"background/#Primal-Problem","page":"Mathematical Background","title":"Primal Problem","text":"ConicIP solves the conic optimization problem\n\nminimize    ½ yᵀQy - cᵀy\nsubject to  Ay - b ∈ K\n            Gy = d\n\nwhere K is a Cartesian product of cones and Q is positive semidefinite.","category":"section"},{"location":"background/#Supported-Cones","page":"Mathematical Background","title":"Supported Cones","text":"Nonnegative orthant (\"R\"): the set of vectors with all nonneg entries, R₊ⁿ = { x ∈ Rⁿ : xᵢ ≥ 0 }.\n\nSecond-order cone (\"Q\"): also called the Lorentz cone, Qⁿ = { (t, x) ∈ R × Rⁿ⁻¹ : ‖x‖₂ ≤ t }.\n\nPositive semidefinite cone (\"S\", experimental): Sⁿ₊ = { X ∈ Sⁿ : X ≽ 0 }. Matrices are stored in vectorized form using vecm, which scales off-diagonal entries by √2 to preserve inner products.","category":"section"},{"location":"background/#Interior-Point-Method","page":"Mathematical Background","title":"Interior-Point Method","text":"ConicIP implements a homogeneous self-dual interior-point method based on the approach described by Andersen, Dahl, and Vandenberghe (2003). The method solves the primal and dual problems simultaneously and can detect infeasibility and unboundedness without a separate Phase I.","category":"section"},{"location":"background/#Nesterov-Todd-Scaling","page":"Mathematical Background","title":"Nesterov-Todd Scaling","text":"At each iteration, the algorithm computes the Nesterov-Todd scaling point such that the scaling operator F satisfies F z = F⁻¹ s = λ, where z and s are the current primal and dual slack variables.\n\nThe scaling matrix type depends on the cone:\n\nCone Scaling type\nNonneg orthant Diagonal — F = Diagonal(√(s./z))\nSecond-order cone SymWoodbury — rank-2 update of a diagonal\nSemidefinite cone VecCongurance — congruence transform","category":"section"},{"location":"background/#Predictor-Corrector-Steps","page":"Mathematical Background","title":"Predictor-Corrector Steps","text":"Each iteration consists of two phases:\n\nPredictor (affine) step: Solve the KKT system with current residuals to estimate how much the complementarity gap can be reduced.\nCorrector (combined) step: Solve a modified system that includes a centering term σμe and a second-order correction. The centering parameter σ is chosen adaptively based on the predictor step length.","category":"section"},{"location":"background/#Convergence-Criteria","page":"Mathematical Background","title":"Convergence Criteria","text":"The solver monitors three residuals:\n\nPrimal feasibility (prFeas): ‖Ay - s - b‖ / (1 + ‖b‖)\nDual feasibility (duFeas): ‖Qy + Gᵀw - Aᵀv - c‖ / (1 + ‖c‖)\nComplementarity (muFeas): sᵀv / (1 + |cᵀy|)\n\nThe solver terminates with status :Optimal when all three residuals fall below the tolerance optTol (default: 1e-6).","category":"section"},{"location":"background/#Troubleshooting-Solver-Output","page":"Mathematical Background","title":"Troubleshooting Solver Output","text":"","category":"section"},{"location":"background/#Status:-:Optimal","page":"Mathematical Background","title":"Status: :Optimal","text":"All convergence criteria met. Check sol.prFeas, sol.duFeas, and sol.muFeas to confirm the solution quality. Values below 1e-8 indicate a high-accuracy solution.","category":"section"},{"location":"background/#Status:-:Infeasible","page":"Mathematical Background","title":"Status: :Infeasible","text":"The solver found a certificate (w, v) proving no feasible point exists. Common causes:\n\nContradictory constraints (e.g., x ≥ 1 and x ≤ 0)\nOverly tight bounds combined with equality constraints\n\nWhat to try: Relax constraints or check problem data for errors.","category":"section"},{"location":"background/#Status:-:Unbounded","page":"Mathematical Background","title":"Status: :Unbounded","text":"The solver found a ray along which the objective decreases without bound. Common causes:\n\nMissing constraints that should bound the feasible region\nQ = 0 (LP) with an unbounded feasible direction\n\nWhat to try: Add bounding constraints or verify the objective.","category":"section"},{"location":"background/#Status:-:Abandoned","page":"Mathematical Background","title":"Status: :Abandoned","text":"The solver stalled — step sizes became too small to make progress. Common causes:\n\nNear-degenerate problem (constraints nearly dependent)\nPoor numerical conditioning of Q or A\nTolerance optTol set too tight for the problem's condition number\n\nWhat to try:\n\nUse preprocess_conicIP to remove redundant constraints\nLoosen optTol (e.g., 1e-5 instead of 1e-8)\nScale the problem data so that entries are of moderate magnitude","category":"section"},{"location":"background/#Status:-:Error","page":"Mathematical Background","title":"Status: :Error","text":"An unexpected error occurred (e.g., singular factorization). This usually indicates a problem with the input data.\n\nWhat to try: Check that Q is positive semidefinite and A has full row rank.","category":"section"},{"location":"background/#Reading-Residuals","page":"Mathematical Background","title":"Reading Residuals","text":"The three residuals in the Solution struct measure different aspects of solution quality:\n\nResidual Measures Good value\nprFeas Constraint satisfaction < optTol\nduFeas KKT stationarity < optTol\nmuFeas Complementary slackness < optTol\n\nIf prFeas is large but duFeas is small, the solver found a nearly optimal point that doesn't quite satisfy the constraints — try scaling.\n\nIf muFeas is large but the others are small, the solver found a feasible point but the duality gap hasn't closed — try more iterations (maxIters).","category":"section"},{"location":"background/#Parameter-Tuning","page":"Mathematical Background","title":"Parameter Tuning","text":"Parameter Default Effect\noptTol 1e-6 Convergence tolerance for all three residuals\nmaxIters 100 Maximum interior-point iterations\nDTB 0.01 Distance-to-boundary parameter; controls step conservatism\nmaxRefinementSteps 3 Iterative refinement steps for KKT solve\ninfeasTol optTol Threshold for infeasibility detection\n\noptTol: Decrease for higher accuracy (e.g., 1e-8); increase if the solver stalls (e.g., 1e-5). Tighter tolerances require more iterations.\n\nDTB: Controls how close the step can get to the cone boundary. Smaller values (e.g., 0.001) are more conservative but more stable; larger values (e.g., 0.1) are more aggressive and may converge faster or oscillate.\n\nmaxIters: Increase if the solver reports :Abandoned after reaching the iteration limit. Most well-conditioned problems converge in 20–50 iterations.","category":"section"},{"location":"background/#References","page":"Mathematical Background","title":"References","text":"E.D. Andersen, C. Roos, and T. Terlaky. \"On implementing a primal-dual interior-point method for conic quadratic optimization.\" Mathematical Programming, 95(2):249-277, 2003.\nY.E. Nesterov and M.J. Todd. \"Self-scaled barriers and interior-point methods for convex programming.\" Mathematics of Operations Research, 22(1):1-42, 1997.\nL. Vandenberghe and S. Boyd. \"Semidefinite programming.\" SIAM Review, 38(1):49-95, 1996.\nM.S. Andersen, J. Dahl, and L. Vandenberghe. \"CVXOPT: A Python package for convex optimization.\" Available at https://cvxopt.org.","category":"section"},{"location":"#ConicIP.jl","page":"Home","title":"ConicIP.jl","text":"ConicIP.jl is a pure-Julia conic interior-point solver for optimization problems with linear, second-order cone, and (experimental) semidefinite constraints.","category":"section"},{"location":"#Why-ConicIP?","page":"Home","title":"Why ConicIP?","text":"Pure Julia — no binary dependencies or external solver installations\nCustom KKT solver callbacks — exploit problem structure for speed\nExtensible — plug in your own factorization at each interior-point iteration\nNesterov-Todd scaling — symmetric primal-dual scaling for good numerical behavior\nInfeasibility detection — returns certificates for infeasible/unbounded problems","category":"section"},{"location":"#Problem-Formulation","page":"Home","title":"Problem Formulation","text":"ConicIP solves problems of the form:\n\nminimize    ½ yᵀQy - cᵀy\nsubject to  Ay ≥_K b\n            Gy  = d\n\nwhere Q ≽ 0 and K is a Cartesian product of cones:\n\nCone Spec Description\nNonnegative orthant (\"R\", n) Linear inequalities\nSecond-order cone (\"Q\", n) Norm constraints\nSemidefinite (experimental) (\"S\", k) Matrix positivity","category":"section"},{"location":"#Quick-Example","page":"Home","title":"Quick Example","text":"using ConicIP, SparseArrays, LinearAlgebra, Random\nRandom.seed!(42)\n\n# Box-constrained QP: minimize ½ y'Qy - c'y subject to 0 ≤ y ≤ 1\nn = 5\nQ = sparse(Diagonal(rand(n) .+ 0.1))\nc = randn(n)\n\n# Constraints: [I; -I] y ≥ [0; -1]\nA = sparse([I(n); -I(n)])\nb = [zeros(n); -ones(n)]\ncone_dims = [(\"R\", 2n)]\n\nsol = conicIP(Q, c, A, b, cone_dims; verbose=false)\nsol.status\n\nround.(sol.y, digits=4)","category":"section"},{"location":"#Two-Ways-to-Use-ConicIP","page":"Home","title":"Two Ways to Use ConicIP","text":"Direct API — full control, supports quadratic objectives:\n\nsol = conicIP(Q, c, A, b, cone_dims; verbose=false)\n\nJuMP/MOI — algebraic modeling, linear objectives only:\n\nusing JuMP, ConicIP\nmodel = Model(ConicIP.Optimizer)\n@variable(model, x[1:n] >= 0)\n@objective(model, Min, sum(x))\noptimize!(model)\n\nSee the JuMP Integration guide for details.","category":"section"},{"location":"#Choosing-a-Solver","page":"Home","title":"Choosing a Solver","text":"ConicIP is a good fit when you need:\n\nA pure-Julia solver with no binary dependencies\nCustom KKT solver callbacks to exploit problem structure\nA solver for moderate-size LP/QP/SOCP problems\n\nFor large-scale production use, consider:\n\nSolver Pure Julia QP SOCP SDP Custom KKT\nConicIP ✓ ✓ ✓ experimental ✓\nCOSMO.jl ✓ ✓ ✓ ✓ ✗\nHypatia.jl ✓ ✓ ✓ ✓ ✗\nSCS ✗ (C) ✗ ✓ ✓ ✗\nECOS ✗ (C) ✗ ✓ ✗ ✗","category":"section"},{"location":"#Contents","page":"Home","title":"Contents","text":"Pages = [\n    \"installation.md\",\n    \"tutorials/generated/getting_started.md\",\n    \"tutorials/generated/lp.md\",\n    \"tutorials/generated/qp.md\",\n    \"tutorials/generated/socp.md\",\n    \"tutorials/generated/sdp.md\",\n    \"guides/jump.md\",\n    \"guides/kkt_solvers.md\",\n    \"guides/preprocessing.md\",\n    \"background.md\",\n    \"api.md\",\n]\nDepth = 2","category":"section"}]
}
